EXPERIMENT 63: LSTM NEURAL NETWORK

Parameters
	epochs:   15
	batch_size:   64
	depth_lstm:   1
	depth_dense:   2
	units_lstm:   256
	reg_n:   l2(5e-1)
	activation:   relu
	batch_norm:   True
	dropout:   0.4
	class_weight:   {0: 1.098901098901099, 1: 11.11111111111111}
	look_back:   500
	stride:   1
	predicted_timestamps:   1
	target_steps_ahead:   2000
	subsampling_factor:   2

Model
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
unified_lstm (UnifiedLSTM)   multiple                  355328    
_________________________________________________________________
batch_normalization_v2 (Batc multiple                  1024      
_________________________________________________________________
dropout (Dropout)            multiple                  0         
_________________________________________________________________
dense (Dense)                multiple                  65792     
_________________________________________________________________
batch_normalization_v2_1 (Ba multiple                  1024      
_________________________________________________________________
dropout_1 (Dropout)          multiple                  0         
_________________________________________________________________
dense_1 (Dense)              multiple                  257       
=================================================================
Total params: 423,425
Trainable params: 422,401
Non-trainable params: 1,024
_________________________________________________________________

Data shape
	X_train:   (81000, 500, 90)
	y_train:   (81000,)
	X_test:   (14751, 500, 90)
	y_test:   (14751,)

Results on train set
	loss_train:   0.0876517229263193
	accuracy_train:   0.9831604938271605
	roc_auc_train:   0.9997994986282579
	recall_train:   1.0

Results on test set
	loss_test:   0.33196636978167365
	accuracy_test:   0.9350552504914921
	roc_auc_test:   0.9777768218750786
	recall_test:   0.9006666666666666

